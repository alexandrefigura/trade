#!/usr/bin/env python3
"""
Script para criar o ZIP do Sistema de Trading Ultra-Otimizado v5.2
Execute este script para gerar trading_system_v5.2.zip com toda a estrutura do projeto
"""

import os
import zipfile
from datetime import datetime

# Definir o conte√∫do de cada arquivo
FILES = {
    "trade_system/__init__.py": '''"""
Sistema de Trading Ultra-Otimizado v5.2

Um sistema de trading algor√≠tmico de alta performance com:
- An√°lise t√©cnica ultra-r√°pida com Numba
- WebSocket para dados em tempo real
- Machine Learning para predi√ß√µes
- Paper trading com dados reais
- Sistema de alertas multi-canal
- Gest√£o de risco avan√ßada
"""

__version__ = "5.2.0"
__author__ = "Trading System Team"
__license__ = "MIT"

# Importa√ß√µes principais para facilitar uso
from trade_system.config import UltraConfigV5, get_config, create_example_config
from trade_system.logging_config import setup_logging, get_logger
from trade_system.cache import UltraFastCache
from trade_system.rate_limiter import RateLimiter, rate_limited
from trade_system.alerts import AlertSystem
from trade_system.signals import OptimizedSignalConsolidator
from trade_system.checkpoint import CheckpointManager

__all__ = [
    'UltraConfigV5',
    'get_config',
    'create_example_config',
    'setup_logging',
    'get_logger',
    'UltraFastCache',
    'RateLimiter',
    'rate_limited',
    'AlertSystem',
    'OptimizedSignalConsolidator',
    'CheckpointManager',
]
''',

    "trade_system/config.py": '''"""
Configura√ß√£o centralizada do sistema de trading
"""
import os
import yaml
import logging
import multiprocessing as mp
from dataclasses import dataclass
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)


@dataclass
class UltraConfigV5:
    """Configura√ß√£o para m√°xima performance"""
    # APIs
    api_key: str = ""
    api_secret: str = ""
    
    # Trading
    symbol: str = "BTCUSDT"
    min_confidence: float = 0.75
    max_position_pct: float = 0.02

    # Par√¢metros de Technical Analysis
    ta_interval_ms: int = 5000
    sma_short_period: int = 9
    sma_long_period: int = 20
    ema_short_period: int = 9
    ema_long_period: int = 20
    rsi_period: int = 14
    rsi_buy_threshold: float = 30.0
    rsi_sell_threshold: float = 70.0
    rsi_confidence: float = 0.8
    sma_cross_confidence: float = 0.75
    bb_period: int = 20
    bb_std_dev: float = 2.0
    bb_confidence: float = 0.7
    pattern_confidence: float = 0.85
    buy_threshold: float = 0.3
    sell_threshold: float = 0.3

    # Filtros
    min_volume_multiplier: float = 1.0
    max_recent_volatility: float = 0.05

    # ATR parameters
    atr_period: int = 14
    tp_multiplier: float = 1.5
    sl_multiplier: float = 1.0

    # Performance
    use_redis: bool = True
    redis_host: str = "localhost"
    redis_port: int = 6379

    # Processamento paralelo
    num_workers: int = mp.cpu_count()
    batch_size: int = 1000

    # Buffers otimizados
    price_buffer_size: int = 10000
    orderbook_buffer_size: int = 100

    # Timing
    main_loop_interval_ms: int = 1000
    gc_interval_cycles: int = 1000

    # Configura√ß√£o avan√ßada
    rate_limit_window: int = 60
    rate_limit_max_calls: int = 1200

    # Prote√ß√µes de mercado
    max_volatility: float = 0.05
    max_spread_bps: float = 20.0
    min_volume_24h: int = 1_000_000

    # Alertas
    enable_alerts: bool = True
    telegram_token: str = ""
    telegram_chat_id: str = ""
    alert_email: str = ""

    # Risk management
    max_daily_loss: float = 0.02

    # Debug mode
    debug_mode: bool = False


def load_config_from_yaml(config_path: str = 'config.yaml') -> Dict[str, Any]:
    """Carrega configura√ß√µes do arquivo YAML"""
    try:
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        logger.warning(f"{config_path} n√£o encontrado, usando configura√ß√µes padr√£o")
        return {}
    except Exception as e:
        logger.error(f"Erro ao carregar {config_path}: {e}")
        return {}


def create_debug_config() -> UltraConfigV5:
    """Cria configura√ß√£o ultra-agressiva para debug e testes"""
    config = UltraConfigV5()
    
    # Par√¢metros extremamente agressivos para garantir sinais
    config.min_confidence = 0.40
    config.rsi_buy_threshold = 45.0
    config.rsi_sell_threshold = 55.0
    config.rsi_confidence = 0.50
    config.bb_confidence = 0.50
    config.sma_cross_confidence = 0.50
    config.pattern_confidence = 0.50
    config.buy_threshold = 0.05
    config.sell_threshold = 0.05
    config.min_volume_multiplier = 0.1
    config.max_recent_volatility = 0.50
    config.max_volatility = 0.50
    config.debug_mode = True
    
    logger.warning("‚ö†Ô∏è MODO DEBUG - Par√¢metros ultra-agressivos ativados!")
    return config


def get_config(debug_mode: bool = False) -> UltraConfigV5:
    """
    Retorna configura√ß√£o completa do sistema
    Prioridade: ENV > YAML > Debug > Default
    """
    if debug_mode:
        config = create_debug_config()
    else:
        config = UltraConfigV5()
    
    # Carregar do YAML
    yaml_cfg = load_config_from_yaml()
    if yaml_cfg:
        # Trading
        trading = yaml_cfg.get('trading', {})
        config.symbol = trading.get('symbol', config.symbol)
        config.min_confidence = trading.get('min_confidence', config.min_confidence)
        config.max_position_pct = trading.get('max_position_pct', config.max_position_pct)
        
        # Risk
        risk = yaml_cfg.get('risk', {})
        config.max_volatility = risk.get('max_volatility', config.max_volatility)
        config.max_spread_bps = risk.get('max_spread_bps', config.max_spread_bps)
        config.max_daily_loss = risk.get('max_daily_loss', config.max_daily_loss)
        config.atr_period = risk.get('atr_period', config.atr_period)
        config.tp_multiplier = risk.get('tp_multiplier', config.tp_multiplier)
        config.sl_multiplier = risk.get('sl_multiplier', config.sl_multiplier)
        
        # TA parameters
        ta = yaml_cfg.get('ta', {})
        for key, value in ta.items():
            if hasattr(config, key):
                setattr(config, key, value)
        
        # Filters
        filters = yaml_cfg.get('filters', {})
        config.min_volume_multiplier = filters.get('min_volume_multiplier', config.min_volume_multiplier)
        config.max_recent_volatility = filters.get('max_recent_volatility', config.max_volatility)
        
        # Performance
        performance = yaml_cfg.get('performance', {})
        config.ta_interval_ms = performance.get('ta_interval_ms', config.ta_interval_ms)
        config.main_loop_interval_ms = performance.get('main_loop_interval_ms', config.main_loop_interval_ms)
        
        # Debug do YAML tem prioridade sobre par√¢metro
        config.debug_mode = yaml_cfg.get('debug_mode', debug_mode)
    
    # ENV vars t√™m prioridade m√°xima
    config.api_key = os.getenv('BINANCE_API_KEY', config.api_key)
    config.api_secret = os.getenv('BINANCE_API_SECRET', config.api_secret)
    config.telegram_token = os.getenv('TELEGRAM_BOT_TOKEN', config.telegram_token)
    config.telegram_chat_id = os.getenv('TELEGRAM_CHAT_ID', config.telegram_chat_id)
    
    return config


def create_example_config(config_path: str = 'config.yaml'):
    """Cria um arquivo config.yaml de exemplo"""
    example_config = """# Configura√ß√£o do Sistema de Trading v5.2

# Modo debug (par√¢metros mais agressivos)
debug_mode: false

trading:
  symbol: "BTCUSDT"
  min_confidence: 0.75  # Confian√ßa m√≠nima para abrir posi√ß√£o (75%)
  max_position_pct: 0.02  # M√°ximo 2% do balance por posi√ß√£o

risk:
  max_volatility: 0.05  # M√°xima volatilidade aceita (5%)
  max_spread_bps: 20  # M√°ximo spread em basis points
  max_daily_loss: 0.02  # Stop loss di√°rio (2%)
  atr_period: 14  # Per√≠odo para c√°lculo do ATR
  tp_multiplier: 1.5  # Take profit em 1.5x ATR
  sl_multiplier: 1.0  # Stop loss em 1x ATR

ta:
  # RSI
  rsi_period: 14
  rsi_buy_threshold: 30  # Compra quando RSI < 30
  rsi_sell_threshold: 70  # Venda quando RSI > 70
  rsi_confidence: 0.8
  
  # Moving Averages
  sma_short_period: 9
  sma_long_period: 20
  ema_short_period: 9
  ema_long_period: 20
  sma_cross_confidence: 0.75
  
  # Bollinger Bands
  bb_period: 20
  bb_std_dev: 2.0
  bb_confidence: 0.7
  
  # Pattern Detection
  pattern_confidence: 0.85
  
  # Thresholds para decis√£o final
  buy_threshold: 0.3
  sell_threshold: 0.3

filters:
  min_volume_multiplier: 1.0  # Volume m√≠nimo em rela√ß√£o √† m√©dia
  max_recent_volatility: 0.05  # M√°xima volatilidade recente (5%)

performance:
  ta_interval_ms: 5000  # Intervalo m√≠nimo entre an√°lises t√©cnicas
  main_loop_interval_ms: 1000  # Intervalo do loop principal
"""
    
    with open(config_path, 'w') as f:
        f.write(example_config)
    logger.info(f"Arquivo {config_path} criado com sucesso!")
''',

    "trade_system/logging_config.py": '''"""
Configura√ß√£o centralizada de logging
"""
import os
import sys
import io
import logging
from datetime import datetime


def setup_logging(
    log_level: str = "INFO",
    log_file: str = None,
    log_dir: str = "logs"
) -> None:
    """
    Configura o sistema de logging de forma centralizada
    
    Args:
        log_level: N√≠vel de logging (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        log_file: Nome do arquivo de log (padr√£o: ultra_v5.log)
        log_dir: Diret√≥rio para logs
    """
    # For√ßa sa√≠da e erro em UTF-8
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    
    # Criar diret√≥rio de logs se n√£o existir
    os.makedirs(log_dir, exist_ok=True)
    
    # Nome do arquivo de log
    if log_file is None:
        log_file = f"trading_{datetime.now().strftime('%Y%m%d')}.log"
    
    log_path = os.path.join(log_dir, log_file)
    
    # Handlers
    handlers = []
    
    # File handler com UTF-8
    file_handler = logging.FileHandler(log_path, encoding='utf-8')
    file_handler.setLevel(getattr(logging, log_level.upper()))
    handlers.append(file_handler)
    
    # Console handler
    console_handler = logging.StreamHandler(stream=sys.stdout)
    console_handler.setLevel(getattr(logging, log_level.upper()))
    handlers.append(console_handler)
    
    # Formato detalhado
    formatter = logging.Formatter(
        '%(asctime)s.%(msecs)03d [%(levelname)s] %(name)s: %(message)s',
        datefmt='%H:%M:%S'
    )
    
    for handler in handlers:
        handler.setFormatter(formatter)
    
    # Configurar root logger
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        handlers=handlers
    )
    
    # Configurar loggers espec√≠ficos
    # Reduzir ru√≠do de bibliotecas externas
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('websocket').setLevel(logging.WARNING)
    logging.getLogger('binance').setLevel(logging.WARNING)
    
    # Log inicial
    logger = logging.getLogger(__name__)
    logger.info(f"Sistema de logging configurado - N√≠vel: {log_level}")
    logger.info(f"Logs salvos em: {log_path}")


def get_logger(name: str) -> logging.Logger:
    """
    Retorna um logger configurado para o m√≥dulo
    
    Args:
        name: Nome do m√≥dulo (geralmente __name__)
        
    Returns:
        Logger configurado
    """
    return logging.getLogger(name)
''',

    "trade_system/cache.py": '''"""
Sistema de cache ultra-r√°pido com Redis e fallback local
"""
import time
import pickle
import redis
from typing import Any, Optional
from trade_system.logging_config import get_logger

logger = get_logger(__name__)


class UltraFastCache:
    """Cache em mem√≥ria com Redis para lat√™ncia < 1ms"""
    
    def __init__(self, config):
        self.config = config
        self.enabled = config.use_redis
        self.local_cache = {}
        self.redis_client = None
        
        if self.enabled:
            self._init_redis()
    
    def _init_redis(self):
        """Inicializa conex√£o com Redis com retry"""
        try:
            self.redis_client = redis.Redis(
                host=self.config.redis_host,
                port=self.config.redis_port,
                decode_responses=False,
                socket_keepalive=True,
                socket_connect_timeout=5,
                health_check_interval=30
            )
            self.redis_client.ping()
            logger.info("‚úÖ Redis conectado com sucesso")
            self.enabled = True
        except redis.exceptions.ConnectionError as e:
            logger.warning(f"‚ö†Ô∏è Redis conex√£o falhou: {e}")
            self.enabled = False
        except redis.exceptions.TimeoutError as e:
            logger.warning(f"‚ö†Ô∏è Redis timeout: {e}")
            self.enabled = False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis erro gen√©rico: {e}")
            self.enabled = False
    
    def get(self, key: str) -> Optional[Any]:
        """Busca ultra-r√°pida no cache com tratamento de erros espec√≠ficos"""
        try:
            if self.enabled and self.redis_client:
                data = self.redis_client.get(key)
                if data:
                    return pickle.loads(data)
            else:
                cache_entry = self.local_cache.get(key)
                if cache_entry and time.time() < cache_entry[1]:
                    return cache_entry[0]
        except redis.exceptions.ConnectionError:
            logger.debug("Redis desconectado, usando cache local")
            self.enabled = False
            return self._get_from_local(key)
        except pickle.UnpicklingError:
            logger.debug(f"Erro ao deserializar cache key: {key}")
            return None
        except Exception as e:
            logger.debug(f"Erro no cache get: {e}")
            return None
        
        return None
    
    def _get_from_local(self, key: str) -> Optional[Any]:
        """Busca no cache local como fallback"""
        cache_entry = self.local_cache.get(key)
        if cache_entry and time.time() < cache_entry[1]:
            return cache_entry[0]
        return None
    
    def set(self, key: str, value: Any, ttl: int = 5):
        """Armazena no cache com TTL e tratamento de erros"""
        try:
            if self.enabled and self.redis_client:
                self.redis_client.setex(key, ttl, pickle.dumps(value))
            else:
                self._set_to_local(key, value, ttl)
        except redis.exceptions.ConnectionError:
            logger.debug("Redis desconectado ao salvar")
            self.enabled = False
            self._set_to_local(key, value, ttl)
        except pickle.PicklingError:
            logger.debug(f"Erro ao serializar valor para key: {key}")
        except Exception as e:
            logger.debug(f"Erro no cache set: {e}")
    
    def _set_to_local(self, key: str, value: Any, ttl: int):
        """Armazena no cache local"""
        self.local_cache[key] = (value, time.time() + ttl)
        # Limpar cache expirado se muito grande
        if len(self.local_cache) > 1000:
            self._cleanup_local_cache()
    
    def _cleanup_local_cache(self):
        """Limpa entradas expiradas do cache local"""
        try:
            now = time.time()
            self.local_cache = {
                k: v for k, v in self.local_cache.items()
                if v[1] > now
            }
            logger.debug(f"Cache local limpo: {len(self.local_cache)} entradas restantes")
        except Exception as e:
            logger.error(f"Erro ao limpar cache: {e}")
    
    def delete(self, key: str):
        """Remove uma chave do cache"""
        try:
            if self.enabled and self.redis_client:
                self.redis_client.delete(key)
            if key in self.local_cache:
                del self.local_cache[key]
        except Exception as e:
            logger.debug(f"Erro ao deletar cache key {key}: {e}")
    
    def clear(self):
        """Limpa todo o cache"""
        try:
            if self.enabled and self.redis_client:
                self.redis_client.flushdb()
            self.local_cache.clear()
            logger.info("Cache limpo completamente")
        except Exception as e:
            logger.error(f"Erro ao limpar cache: {e}")
    
    def get_stats(self) -> dict:
        """Retorna estat√≠sticas do cache"""
        stats = {
            'redis_enabled': self.enabled,
            'local_cache_size': len(self.local_cache),
            'redis_connected': False
        }
        
        if self.enabled and self.redis_client:
            try:
                info = self.redis_client.info()
                stats['redis_connected'] = True
                stats['redis_memory_used'] = info.get('used_memory_human', 'N/A')
                stats['redis_keys'] = self.redis_client.dbsize()
            except:
                pass
        
        return stats
''',

    "trade_system/rate_limiter.py": '''"""
Sistema de rate limiting para prote√ß√£o de API
"""
import time
import threading
from collections import defaultdict
from functools import wraps
from typing import Dict, Callable
from trade_system.logging_config import get_logger

logger = get_logger(__name__)


class RateLimiter:
    """Controle de rate limiting para prote√ß√£o de API"""
    
    def __init__(self, config):
        self.config = config
        self.calls = defaultdict(list)
        self.lock = threading.Lock()
        self.window = config.rate_limit_window
        self.max_calls = config.rate_limit_max_calls
    
    def check_limit(self, endpoint: str = 'default') -> bool:
        """Verifica se pode fazer chamada"""
        with self.lock:
            now = time.time()
            # Limpar chamadas antigas
            self.calls[endpoint] = [
                t for t in self.calls[endpoint] 
                if now - t < self.window
            ]
            
            # Verificar limite
            if len(self.calls[endpoint]) >= self.max_calls:
                return False
            
            # Registrar chamada
            self.calls[endpoint].append(now)
            return True
    
    def wait_if_needed(self, endpoint: str = 'default'):
        """Aguarda se necess√°rio para respeitar rate limit"""
        while not self.check_limit(endpoint):
            time.sleep(0.1)
    
    def get_usage(self) -> Dict:
        """Retorna uso atual dos rate limits"""
        with self.lock:
            now = time.time()
            usage = {}
            for endpoint, calls in self.calls.items():
                recent_calls = [t for t in calls if now - t < self.window]
                usage[endpoint] = {
                    'calls': len(recent_calls),
                    'limit': self.max_calls,
                    'percentage': len(recent_calls) / self.max_calls * 100,
                    'time_until_reset': self.window - (now - min(recent_calls)) if recent_calls else 0
                }
            return usage
    
    def get_wait_time(self, endpoint: str = 'default') -> float:
        """Retorna tempo de espera necess√°rio em segundos"""
        with self.lock:
            now = time.time()
            self.calls[endpoint] = [
                t for t in self.calls[endpoint] 
                if now - t < self.window
            ]
            
            if len(self.calls[endpoint]) >= self.max_calls:
                oldest_call = min(self.calls[endpoint])
                wait_time = self.window - (now - oldest_call)
                return max(0, wait_time)
            
            return 0
    
    def reset(self, endpoint: str = None):
        """Reseta contador de chamadas"""
        with self.lock:
            if endpoint:
                self.calls[endpoint] = []
            else:
                self.calls.clear()
            logger.info(f"Rate limiter resetado para: {endpoint or 'todos endpoints'}")


def rate_limited(endpoint: str = 'default', wait: bool = True):
    """
    Decorator para aplicar rate limiting
    
    Args:
        endpoint: Nome do endpoint para controle separado
        wait: Se True, aguarda automaticamente. Se False, levanta exce√ß√£o
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def async_wrapper(self, *args, **kwargs):
            if hasattr(self, 'rate_limiter'):
                if wait:
                    self.rate_limiter.wait_if_needed(endpoint)
                else:
                    if not self.rate_limiter.check_limit(endpoint):
                        wait_time = self.rate_limiter.get_wait_time(endpoint)
                        raise RateLimitExceeded(
                            f"Rate limit exceeded for {endpoint}. "
                            f"Wait {wait_time:.1f}s"
                        )
            return await func(self, *args, **kwargs)
        
        @wraps(func)
        def sync_wrapper(self, *args, **kwargs):
            if hasattr(self, 'rate_limiter'):
                if wait:
                    self.rate_limiter.wait_if_needed(endpoint)
                else:
                    if not self.rate_limiter.check_limit(endpoint):
                        wait_time = self.rate_limiter.get_wait_time(endpoint)
                        raise RateLimitExceeded(
                            f"Rate limit exceeded for {endpoint}. "
                            f"Wait {wait_time:.1f}s"
                        )
            return func(self, *args, **kwargs)
        
        # Retornar wrapper apropriado baseado no tipo da fun√ß√£o
        if asyncio.iscoroutinefunction(func):
            return async_wrapper
        else:
            return sync_wrapper
    
    return decorator


class RateLimitExceeded(Exception):
    """Exce√ß√£o levantada quando rate limit √© excedido"""
    pass


# Importa√ß√£o condicional do asyncio
try:
    import asyncio
except ImportError:
    # Fallback para sistemas sem asyncio
    asyncio = None
''',

    "trade_system/alerts.py": '''"""
Sistema de alertas multi-canal com cooldown
"""
import time
import asyncio
import aiohttp
from typing import Dict, Optional
from datetime import datetime
from trade_system.logging_config import get_logger

logger = get_logger(__name__)


class AlertSystem:
    """Sistema de alertas multi-canal"""
    
    def __init__(self, config):
        self.config = config
        self.last_alert_time = {}
        self.alert_cooldown = 300  # 5 minutos entre alertas do mesmo tipo
        self.alert_count = {}
        
    async def send_alert(
        self, 
        title: str, 
        message: str, 
        priority: str = 'info',
        force: bool = False
    ) -> bool:
        """
        Envia alerta por m√∫ltiplos canais
        
        Args:
            title: T√≠tulo do alerta
            message: Mensagem detalhada
            priority: 'info', 'warning', 'critical'
            force: Ignora cooldown se True
            
        Returns:
            True se alerta foi enviado
        """
        if not self.config.enable_alerts:
            return False
        
        # Verificar cooldown
        alert_key = f"{title}_{priority}"
        
        if not force and alert_key in self.last_alert_time:
            if time.time() - self.last_alert_time[alert_key] < self.alert_cooldown:
                logger.debug(f"Alerta ignorado por cooldown: {alert_key}")
                return False
        
        self.last_alert_time[alert_key] = time.time()
        self.alert_count[alert_key] = self.alert_count.get(alert_key, 0) + 1
        
        # Log sempre
        self._log_alert(title, message, priority)
        
        # Enviar por canais configurados
        tasks = []
        
        if self.config.telegram_token and self.config.telegram_chat_id:
            tasks.append(self._send_telegram(title, message, priority))
        
        if priority == 'critical' and self.config.alert_email:
            tasks.append(self._send_email(title, message))
        
        # Executar envios em paralelo
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Log erros
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"Erro ao enviar alerta: {result}")
        
        return True
    
    def _log_alert(self, title: str, message: str, priority: str):
        """Log local do alerta"""
        emoji = {
            'critical': 'üö®',
            'warning': '‚ö†Ô∏è',
            'info': '‚ÑπÔ∏è'
        }.get(priority, 'üì¢')
        
        log_message = f"{emoji} {title}: {message}"
        
        if priority == 'critical':
            logger.critical(log_message)
        elif priority == 'warning':
            logger.warning(log_message)
        else:
            logger.info(log_message)
    
    async def _send_telegram(self, title: str, message: str, priority: str):
        """Envia alerta via Telegram"""
        try:
            emoji = {
                'critical': 'üö®',
                'warning': '‚ö†Ô∏è',
                'info': '‚ÑπÔ∏è'
            }.get(priority, 'üì¢')
            
            # Formatar mensagem
            timestamp = datetime.now().strftime('%H:%M:%S')
            text = f"{emoji} *{title}*\\n\\n{message}\\n\\n__{timestamp}__"
            
            # Limitar tamanho da mensagem
            if len(text) > 4096:
                text = text[:4093] + "..."
            
            url = f"https://api.telegram.org/bot{self.config.telegram_token}/sendMessage"
            data = {
                'chat_id': self.config.telegram_chat_id,
                'text': text,
                'parse_mode': 'Markdown',
                'disable_notification': priority == 'info'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=data) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"Erro Telegram API: {response.status} - {error_text}")
                    else:
                        logger.debug(f"Alerta Telegram enviado: {title}")
                
        except Exception as e:
            logger.error(f"Erro ao enviar alerta Telegram: {e}")
    
    async def _send_email(self, title: str, message: str):
        """
        Envia alerta via email (implementar conforme necess√°rio)
        Placeholder para integra√ß√£o com servi√ßo de email
        """
        logger.info(f"Email alert (n√£o implementado): {title}")
        # TODO: Implementar envio de email via SMTP ou API (SendGrid, etc)
    
    def get_alert_stats(self) -> Dict:
        """Retorna estat√≠sticas de alertas"""
        stats = {
            'total_alerts': sum(self.alert_count.values()),
            'alerts_by_type': dict(self.alert_count),
            'channels_configured': {
                'telegram': bool(self.config.telegram_token),
                'email': bool(self.config.alert_email)
            }
        }
        
        # Alertas recentes
        now = time.time()
        recent_alerts = []
        for alert_key, last_time in self.last_alert_time.items():
            if now - last_time < 3600:  # √öltima hora
                recent_alerts.append({
                    'key': alert_key,
                    'time_ago': int(now - last_time),
                    'count': self.alert_count.get(alert_key, 0)
                })
        
        stats['recent_alerts'] = recent_alerts
        return stats
''',

    "trade_system/signals.py": '''"""
Sistema de consolida√ß√£o de sinais otimizado
"""
import time
import numpy as np
from collections import deque
from typing import List, Tuple, Dict
from trade_system.logging_config import get_logger

logger = get_logger(__name__)


class OptimizedSignalConsolidator:
    """Consolida√ß√£o ultra-r√°pida de sinais"""
    
    def __init__(self):
        self.weights = {
            'technical': 0.35,
            'orderbook': 0.35,
            'ml': 0.30
        }
        self.signal_history = deque(maxlen=100)
        self.performance_by_source = {
            'technical': {'correct': 0, 'total': 0},
            'orderbook': {'correct': 0, 'total': 0},
            'ml': {'correct': 0, 'total': 0}
        }
    
    def consolidate(self, signals: List[Tuple[str, str, float]]) -> Tuple[str, float]:
        """
        Consolida sinais com vota√ß√£o ponderada otimizada
        
        Args:
            signals: Lista de tuplas (source, action, confidence)
            
        Returns:
            Tupla (action, confidence)
        """
        if not signals:
            return 'HOLD', 0.0
        
        # Vetorizar c√°lculos
        actions = []
        confidences = []
        weights = []
        signal_details = {}
        
        for source, action, confidence in signals:
            # Converter a√ß√£o para n√∫mero
            action_value = 1 if action == 'BUY' else (-1 if action == 'SELL' else 0)
            actions.append(action_value)
            confidences.append(confidence)
            
            # Peso adaptativo baseado em performance
            base_weight = self.weights.get(source, 0.25)
            adaptive_weight = self._get_adaptive_weight(source, base_weight)
            weights.append(adaptive_weight)
            
            signal_details[source] = (action, confidence)
        
        actions = np.array(actions)
        confidences = np.array(confidences)
        weights = np.array(weights)
        
        # Score ponderado
        weighted_score = np.sum(actions * confidences * weights) / np.sum(weights)
        avg_confidence = np.average(confidences, weights=weights)
        
        # Decis√£o final com thresholds adaptativos
        buy_threshold = 0.3
        sell_threshold = -0.3
        
        if weighted_score > buy_threshold:
            final_action = 'BUY'
        elif weighted_score < sell_threshold:
            final_action = 'SELL'
        else:
            final_action = 'HOLD'
            avg_confidence *= 0.5  # Reduzir confian√ßa em HOLD
        
        # Registrar no hist√≥rico
        self.signal_history.append({
            'timestamp': time.time(),
            'action': final_action,
            'confidence': avg_confidence,
            'weighted_score': weighted_score,
            'signals': signal_details,
            'weights_used': dict(zip([s[0] for s in signals], weights))
        })
        
        # Log para sinais fortes
        if avg_confidence > 0.8 and final_action != 'HOLD':
            logger.info(f"üéØ Sinal forte consolidado: {final_action} ({avg_confidence:.2%})")
        
        return final_action, avg_confidence
    
    def _get_adaptive_weight(self, source: str, base_weight: float) -> float:
        """Ajusta peso baseado em performance hist√≥rica"""
        perf = self.performance_by_source.get(source, {})
        total = perf.get('total', 0)
        
        if total < 10:  # Poucos dados, usar peso base
            return base_weight
        
        # Taxa de acerto
        accuracy = perf.get('correct', 0) / total
        
        # Ajustar peso: aumentar se acima de 60%, diminuir se abaixo de 40%
        if accuracy > 0.6:
            return base_weight * 1.2
        elif accuracy < 0.4:
            return base_weight * 0.8
        else:
            return base_weight
    
    def update_performance(self, source: str, was_correct: bool):
        """Atualiza m√©tricas de performance por fonte"""
        if source in self.performance_by_source:
            self.performance_by_source[source]['total'] += 1
            if was_correct:
                self.performance_by_source[source]['correct'] += 1
    
    def get_signal_statistics(self) -> Dict:
        """Retorna estat√≠sticas dos sinais recentes"""
        if not self.signal_history:
            return {
                'total_signals': 0,
                'buy_signals': 0,
                'sell_signals': 0,
                'hold_signals': 0,
                'avg_confidence': 0
            }
        
        recent_signals = list(self.signal_history)
        buy_count = sum(1 for s in recent_signals if s['action'] == 'BUY')
        sell_count = sum(1 for s in recent_signals if s['action'] == 'SELL')
        hold_count = sum(1 for s in recent_signals if s['action'] == 'HOLD')
        
        return {
            'total_signals': len(recent_signals),
            'buy_signals': buy_count,
            'sell_signals': sell_count,
            'hold_signals': hold_count,
            'avg_confidence': np.mean([s['confidence'] for s in recent_signals]),
            'performance_by_source': dict(self.performance_by_source)
        }
''',

    "trade_system/checkpoint.py": '''"""
Sistema de checkpoint e recovery
"""
import os
import json
import pickle
import gzip
from datetime import datetime
from typing import Dict, Optional, Any
from trade_system.logging_config import get_logger

logger = get_logger(__name__)


class CheckpointManager:
    """Gerenciador de checkpoints para recupera√ß√£o r√°pida"""
    
    def __init__(self, checkpoint_dir: str = "checkpoints"):
        self.checkpoint_dir = checkpoint_dir
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        # Configura√ß√µes
        self.checkpoint_interval = 300  # 5 minutos
        self.last_checkpoint = 0
        self.max_checkpoints = 10
        self.use_compression = True
    
    def save_checkpoint(self, state: Dict[str, Any]) -> bool:
        """
        Salva estado do sistema em checkpoint
        
        Args:
            state: Dicion√°rio com estado completo do sistema
            
        Returns:
            True se salvou com sucesso
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(self.checkpoint_dir, f"checkpoint_{timestamp}.pkl")
            
            # Adicionar metadados
            state['checkpoint_time'] = datetime.now()
            state['checkpoint_version'] = 'v5.2'
            
            # Salvar com ou sem compress√£o
            if self.use_compression:
                with gzip.open(filename, 'wb') as f:
                    pickle.dump(state, f)
            else:
                with open(filename, 'wb') as f:
                    pickle.dump(state, f)
            
            # Limpar checkpoints antigos
            self._cleanup_old_checkpoints()
            
            logger.info(f"‚úÖ Checkpoint salvo: {filename}")
            
            # Salvar resumo em JSON
            self._save_summary(state, filename)
            
            self.last_checkpoint = datetime.now().timestamp()
            return True
            
        except Exception as e:
            logger.error(f"Erro ao salvar checkpoint: {e}")
            return False
    
    def load_latest_checkpoint(self) -> Optional[Dict[str, Any]]:
        """
        Carrega checkpoint mais recente
        
        Returns:
            Estado do sistema ou None
        """
        try:
            checkpoint_file = self._get_latest_checkpoint_file()
            
            if not checkpoint_file:
                logger.info("Nenhum checkpoint encontrado")
                return None
            
            # Carregar com ou sem compress√£o
            if checkpoint_file.endswith('.pkl'):
                try:
                    with gzip.open(checkpoint_file, 'rb') as f:
                        state = pickle.load(f)
                except:
                    with open(checkpoint_file, 'rb') as f:
                        state = pickle.load(f)
            
            logger.info(f"‚úÖ Checkpoint carregado: {checkpoint_file}")
            self._log_checkpoint_info(state)
            
            return state
            
        except Exception as e:
            logger.error(f"Erro ao carregar checkpoint: {e}")
            return None
    
    def should_checkpoint(self) -> bool:
        """Verifica se deve fazer checkpoint"""
        return (datetime.now().timestamp() - self.last_checkpoint) > self.checkpoint_interval
    
    def update_checkpoint_time(self):
        """Atualiza tempo do √∫ltimo checkpoint"""
        self.last_checkpoint = datetime.now().timestamp()
    
    def list_checkpoints(self) -> list:
        """Lista todos os checkpoints dispon√≠veis"""
        files = []
        for f in os.listdir(self.checkpoint_dir):
            if f.startswith("checkpoint_") and f.endswith(".pkl"):
                filepath = os.path.join(self.checkpoint_dir, f)
                summary_file = filepath.replace('.pkl', '_summary.json')
                
                info = {
                    'filename': f,
                    'filepath': filepath,
                    'size': os.path.getsize(filepath),
                    'modified': datetime.fromtimestamp(os.path.getmtime(filepath))
                }
                
                # Tentar carregar resumo
                if os.path.exists(summary_file):
                    try:
                        with open(summary_file, 'r') as sf:
                            info['summary'] = json.load(sf)
                    except:
                        pass
                
                files.append(info)
        
        return sorted(files, key=lambda x: x['modified'], reverse=True)
    
    def delete_checkpoint(self, filename: str) -> bool:
        """
        Deleta um checkpoint espec√≠fico
        
        Args:
            filename: Nome do arquivo do checkpoint
            
        Returns:
            True se deletou com sucesso
        """
        try:
            filepath = os.path.join(self.checkpoint_dir, filename)
            if os.path.exists(filepath):
                os.remove(filepath)
                
                # Remover summary tamb√©m
                summary_file = filepath.replace('.pkl', '_summary.json')
                if os.path.exists(summary_file):
                    os.remove(summary_file)
                
                logger.info(f"Checkpoint deletado: {filename}")
                return True
            return False
        except Exception as e:
            logger.error(f"Erro ao deletar checkpoint: {e}")
            return False
    
    def _get_latest_checkpoint_file(self) -> Optional[str]:
        """Retorna caminho do checkpoint mais recente"""
        checkpoints = self.list_checkpoints()
        if checkpoints:
            return checkpoints[0]['filepath']
        return None
    
    def _cleanup_old_checkpoints(self):
        """Remove checkpoints antigos, mantendo apenas os N mais recentes"""
        try:
            checkpoints = self.list_checkpoints()
            
            if len(checkpoints) > self.max_checkpoints:
                for checkpoint in checkpoints[self.max_checkpoints:]:
                    self.delete_checkpoint(checkpoint['filename'])
                    
        except Exception as e:
            logger.error(f"Erro ao limpar checkpoints: {e}")
    
    def _save_summary(self, state: Dict, checkpoint_file: str):
        """Salva resumo do checkpoint em JSON"""
        try:
            summary_file = checkpoint_file.replace('.pkl', '_summary.json')
            
            summary = {
                'timestamp': state.get('checkpoint_time', datetime.now()).isoformat(),
                'balance': state.get('balance', 0),
                'total_trades': state.get('performance_stats', {}).get('total_trades', 0),
                'daily_pnl': state.get('daily_pnl', 0),
                'position': bool(state.get('position')),
                'is_paper_trading': state.get('is_paper_trading', True)
            }
            
            with open(summary_file, 'w') as f:
                json.dump(summary, f, indent=2)
                
        except Exception as e:
            logger.debug(f"Erro ao salvar resumo: {e}")
    
    def _log_checkpoint_info(self, state: Dict):
        """Loga informa√ß√µes do checkpoint carregado"""
        try:
            logger.info(f"   Balan√ßo: ${state.get('balance', 0):,.2f}")
            logger.info(f"   Trades: {state.get('performance_stats', {}).get('total_trades', 0)}")
            logger.info(f"   Tempo: {state.get('checkpoint_time', 'N/A')}")
            
            if state.get('position'):
                pos = state['position']
                logger.info(f"   Posi√ß√£o aberta: {pos.get('side', 'N/A')} @ ${pos.get('entry_price', 0):,.2f}")
        except:
            pass
''',

    "trade_system/utils.py": '''"""
Fun√ß√µes utilit√°rias gen√©ricas
"""
import numpy as np
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
from trade_system.logging_config import get_logger

logger = get_logger(__name__)


def calculate_atr(
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    period: int = 14
) -> np.ndarray:
    """
    Calcula o ATR (Average True Range)
    
    Args:
        high: Array de pre√ßos m√°ximos
        low: Array de pre√ßos m√≠nimos
        close: Array de pre√ßos de fechamento
        period: Per√≠odo para c√°lculo da m√©dia
        
    Returns:
        Array com valores de ATR
    """
    if len(close) < 2:
        return np.full_like(close, np.nan)
    
    # True Range
    tr = np.maximum(
        high[1:] - low[1:],
        np.maximum(
            np.abs(high[1:] - close[:-1]),
            np.abs(low[1:] - close[:-1])
        )
    )
    
    # M√©dia m√≥vel simples do TR
    if len(tr) >= period:
        atr = np.convolve(tr, np.ones(period)/period, mode='valid')
        # Padronizar para o mesmo tamanho de close
        return np.concatenate([np.full(len(close) - len(atr), np.nan), atr])
    else:
        return np.full_like(close, np.nan)


def calculate_atr_from_prices(
    prices: np.ndarray,
    period: int = 14,
    volatility_factor: float = 0.5
) -> Optional[float]:
    """
    Calcula ATR aproximado usando apenas pre√ßos de fechamento
    
    Args:
        prices: Array de pre√ßos
        period: Per√≠odo para c√°lculo
        volatility_factor: Fator para aproximar high/low
        
    Returns:
        Valor ATR aproximado ou None
    """
    if len(prices) < period:
        return None
    
    # Aproximar high/low usando volatilidade
    volatility = np.std(prices[-period:])
    
    # Criar pseudo-OHLC
    high = prices + volatility * volatility_factor
    low = prices - volatility * volatility_factor
    close = prices
    
    # Calcular ATR
    atr_values = calculate_atr(high, low, close, period)
    
    # Retornar √∫ltimo valor v√°lido
    if len(atr_values) > 0 and not np.isnan(atr_values[-1]):
        return float(atr_values[-1])
    
    # Fallback: usar volatilidade * fator
    return volatility * 1.5


def format_price(price: float, decimals: int = 2) -> str:
    """Formata pre√ßo com separadores de milhares"""
    return f"${price:,.{decimals}f}"


def format_percentage(value: float, decimals: int = 2) -> str:
    """Formata percentual com sinal"""
    return f"{value*100:+.{decimals}f}%"


def calculate_position_metrics(
    entry_price: float,
    current_price: float,
    quantity: float,
    side: str,
    fees: float = 0
) -> Dict[str, float]:
    """
    Calcula m√©tricas de uma posi√ß√£o
    
    Returns:
        Dict com pnl, pnl_pct, value, etc
    """
    if side == 'BUY':
        pnl = (current_price - entry_price) * quantity
        pnl_pct = (current_price - entry_price) / entry_price
    else:  # SELL
        pnl = (entry_price - current_price) * quantity
        pnl_pct = (entry_price - current_price) / entry_price
    
    pnl_after_fees = pnl - fees
    current_value = current_price * quantity
    
    return {
        'pnl': pnl,
        'pnl_after_fees': pnl_after_fees,
        'pnl_pct': pnl_pct,
        'current_value': current_value,
        'fees': fees
    }


def calculate_sharpe_ratio(
    returns: np.ndarray,
    periods_per_year: int = 252
) -> float:
    """
    Calcula Sharpe Ratio
    
    Args:
        returns: Array de retornos
        periods_per_year: 252 para daily, 52 para weekly, etc
        
    Returns:
        Sharpe Ratio anualizado
    """
    if len(returns) < 2:
        return 0.0
    
    mean_return = np.mean(returns)
    std_return = np.std(returns)
    
    if std_return == 0:
        return 0.0
    
    return np.sqrt(periods_per_year) * mean_return / std_return


def calculate_max_drawdown(equity_curve: List[float]) -> float:
    """
    Calcula drawdown m√°ximo
    
    Args:
        equity_curve: Lista de valores de equity
        
    Returns:
        Drawdown m√°ximo como percentual (0-1)
    """
    if len(equity_curve) < 2:
        return 0.0
    
    peak = equity_curve[0]
    max_dd = 0.0
    
    for value in equity_curve[1:]:
        if value > peak:
            peak = value
        else:
            dd = (peak - value) / peak
            max_dd = max(max_dd, dd)
    
    return max_dd


def is_market_open() -> bool:
    """Verifica se o mercado crypto est√° operacional (sempre True)"""
    return True


def get_time_until_next_candle(interval_minutes: int = 5) -> int:
    """
    Calcula segundos at√© pr√≥ximo candle
    
    Args:
        interval_minutes: Intervalo do candle em minutos
        
    Returns:
        Segundos at√© pr√≥ximo candle
    """
    now = datetime.now()
    current_minutes = now.minute
    minutes_in_interval = current_minutes % interval_minutes
    minutes_until_next = interval_minutes - minutes_in_interval
    
    return minutes_until_next * 60 - now.second


def validate_price_data(prices: np.ndarray) -> bool:
    """
    Valida array de pre√ßos
    
    Returns:
        True se dados s√£o v√°lidos
    """
    if len(prices) == 0:
        return False
    
    if np.any(prices <= 0):
        return False
    
    if np.any(np.isnan(prices)) or np.any(np.isinf(prices)):
        return False
    
    # Verificar varia√ß√£o m√≠nima
    if np.std(prices) == 0:
        return False
    
    return True


def safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:
    """Divis√£o segura com valor padr√£o"""
    if denominator == 0:
        return default
    return numerator / denominator


def clamp(value: float, min_value: float, max_value: float) -> float:
    """Limita valor entre min e max"""
    return max(min_value, min(value, max_value))
''',

    "trade_system/analysis/__init__.py": '''"""
M√≥dulos de an√°lise do sistema de trading
"""
from trade_system.analysis.technical import (
    UltraFastTechnicalAnalysis,
    calculate_sma_fast,
    calculate_ema_fast,
    calculate_rsi_fast,
    calculate_bollinger_bands_fast,
    detect_patterns_fast,
    filter_low_volume_and_volatility
)

__all__ = [
    'UltraFastTechnicalAnalysis',
    'calculate_sma_fast',
    'calculate_ema_fast',
    'calculate_rsi_fast',
    'calculate_bollinger_bands_fast',
    'detect_patterns_fast',
    'filter_low_volume_and_volatility'
]
''',

    "trade_system/analysis/technical.py": '''"""
An√°lise t√©cnica ultra-r√°pida com NumPy e Numba
"""
import time
import numpy as np
import numba as nb
from numba import njit
from typing import Tuple, Optional, Dict
from trade_system.logging_config import get_logger

logger = get_logger(__name__)


# ===========================
# FUN√á√ïES NUMBA ULTRA-R√ÅPIDAS
# ===========================

@nb.jit(nopython=True, cache=True, fastmath=True)
def calculate_sma_fast(prices: np.ndarray, period: int) -> np.ndarray:
    """SMA ultra-r√°pida com Numba"""
    n = len(prices)
    sma = np.empty(n, dtype=np.float32)
    sma[:period-1] = np.nan
    
    # Primeira m√©dia
    sma[period-1] = np.mean(prices[:period])
    
    # Sliding window otimizado
    for i in range(period, n):
        sma[i] = sma[i-1] + (prices[i] - prices[i-period]) / period
    
    return sma


@nb.jit(nopython=True, cache=True, fastmath=True)
def calculate_ema_fast(prices: np.ndarray, period: int) -> np.ndarray:
    """EMA ultra-r√°pida com Numba"""
    alpha = 2.0 / (period + 1)
    ema = np.empty_like(prices)
    ema[0] = prices[0]
    
    for i in range(1, len(prices)):
        ema[i] = alpha * prices[i] + (1 - alpha) * ema[i-1]
    
    return ema


@nb.jit(nopython=True, cache=True, fastmath=True)
def calculate_rsi_fast(prices: np.ndarray, period: int = 14) -> np.ndarray:
    """RSI ultra-r√°pido com Numba"""
    n = len(prices)
    rsi = np.empty(n, dtype=np.float32)
    rsi[:period] = np.nan
    
    # Calcular diferen√ßas
    deltas = np.diff(prices)
    gains = np.maximum(deltas, 0)
    losses = -np.minimum(deltas, 0)
    
    # M√©dias iniciais
    avg_gain = np.mean(gains[:period])
    avg_loss = np.mean(losses[:period])
    
    # RSI inicial
    if avg_loss != 0:
        rs = avg_gain / avg_loss
        rsi[period] = 100 - (100 / (1 + rs))
    else:
        rsi[period] = 100
    
    # C√°lculo incremental
    for i in range(period + 1, n):
        avg_gain = (avg_gain * (period - 1) + gains[i-1]) / period
        avg_loss = (avg_loss * (period - 1) + losses[i-1]) / period
        
        if avg_loss != 0:
            rs = avg_gain / avg_loss
            rsi[i] = 100 - (100 / (1 + rs))
        else:
            rsi[i] = 100
    
    return rsi


@nb.jit(nopython=True, cache=True, fastmath=True)
def calculate_bollinger_bands_fast(
    prices: np.ndarray, 
    period: int = 20, 
    std_dev: float = 2.0
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """Bollinger Bands ultra-r√°pidas"""
    sma = calculate_sma_fast(prices, period)
    
    # Desvio padr√£o rolling
    n = len(prices)
    std = np.empty(n, dtype=np.float32)
    std[:period-1] = np.nan
    
    for i in range(period-1, n):
        std[i] = np.std(prices[i-period+1:i+1])
    
    upper = sma + std_dev * std
    lower = sma - std_dev * std
    
    return upper, sma, lower


@nb.jit(nopython=True, cache=True, fastmath=True)
def detect_patterns_fast(prices: np.ndarray, volumes: np.ndarray) -> int:
    """
    Detec√ß√£o de padr√µes ultra-r√°pida
    Retorna: -1 (venda), 0 (neutro), 1 (compra)
    """
    if len(prices) < 200:
        return 0
    
    # Validar dados
    if np.std(prices[-50:]) == 0:
        return 0
    
    # Momentum
    momentum = (prices[-1] - prices[-10]) / prices[-10]
    
    # Volume anormal
    avg_volume = np.mean(volumes[-20:])
    volume_spike = volumes[-1] > avg_volume * 1.5
    
    # Breakout detection
    high_20 = np.max(prices[-20:])
    low_20 = np.min(prices[-20:])
    
    if prices[-1] > high_20 * 0.995 and volume_spike and momentum > 0.001:
        return 1  # Sinal de compra
    elif prices[-1] < low_20 * 1.005 and volume_spike and momentum < -0.001:
        return -1  # Sinal de venda
    
    return 0  # Neutro


def filter_low_volume_and_volatility(
    prices: np.ndarray,
    volumes: np.ndarray,
    min_volume_multiplier: float,
    max_recent_volatility: float
) -> Optional[Tuple[str, float, Dict]]:
    """
    Cancela sinais se o volume estiver baixo ou a volatilidade muito alta.
    Retorna ('HOLD', 0.5, {...}) para cancelar, ou None para continuar.
    """
    # Filtro de volume
    if len(volumes) >= 20:
        avg_vol20 = np.mean(volumes[-20:])
        if volumes[-1] < avg_vol20 * min_volume_multiplier:
            logger.debug(f"Volume baixo: {volumes[-1]:.2f} < {avg_vol20 * min_volume_multiplier:.2f}")
            return 'HOLD', 0.5, {'reason': 'Filtrado por volume'}
    
    # Filtro de volatilidade recente
    if len(prices) >= 50:
        recent_vol = np.std(prices[-50:]) / np.mean(prices[-50:])
        if recent_vol > max_recent_volatility:
            logger.debug(f"Volatilidade alta: {recent_vol:.4f} > {max_recent_volatility:.4f}")
            return 'HOLD', 0.5, {'reason': 'Volatilidade alta'}
    
    return None


class UltraFastTechnicalAnalysis:
    """An√°lise t√©cnica com NumPy/Numba para m√°xima velocidade"""
    
    def __init__(self, config):
        self.config = config
        self.last_calculation_time = 0
        self.calculation_interval = config.ta_interval_ms / 1000.0
        self._cached_signal = ('HOLD', 0.5, {'cached': True})
        self.signal_count = {'BUY': 0, 'SELL': 0, 'HOLD': 0}
    
    def analyze(self, prices: np.ndarray, volumes: np.ndarray) -> Tuple[str, float, Dict]:
        """An√°lise t√©cnica completa ultra-r√°pida"""
        now = time.time()
        
        # Valida√ß√µes
        if len(prices) < 200:
            return 'HOLD', 0.5, {'reason': 'Dados insuficientes'}
        
        if np.std(prices[-50:]) == 0:
            return 'HOLD', 0.5, {'reason': 'Dados inv√°lidos - sem varia√ß√£o'}
        
        if np.any(prices <= 0) or np.any(np.isnan(prices)) or np.any(np.isinf(prices)):
            return 'HOLD', 0.5, {'reason': 'Dados inv√°lidos - valores anormais'}
        
        # Respeita intervalo m√≠nimo entre c√°lculos
        if now - self.last_calculation_time < self.calculation_interval:
            return self._cached_signal
        
        # Filtros (se n√£o estiver em debug)
        if not self.config.debug_mode:
            filter_result = filter_low_volume_and_volatility(
                prices,
                volumes,
                self.config.min_volume_multiplier,
                self.config.max_recent_volatility
            )
            if filter_result is not None:
                return filter_result
        
        start_ts = time.perf_counter()
        
        # Calcular indicadores
        sma_short = calculate_sma_fast(prices, self.config.sma_short_period)
        sma_long = calculate_sma_fast(prices, self.config.sma_long_period)
        ema_short = calculate_ema_fast(prices, self.config.ema_short_period)
        ema_long = calculate_ema_fast(prices, self.config.ema_long_period)
        rsi_vals = calculate_rsi_fast(prices, self.config.rsi_period)
        bb_upper, bb_mid, bb_lower = calculate_bollinger_bands_fast(
            prices, self.config.bb_period, self.config.bb_std_dev
        )
        pattern_signal = detect_patterns_fast(prices, volumes)
        
        # Gerar sinais
        signals = []
        confs = []
        signal_reasons = []
        
        # RSI
        current_rsi = rsi_vals[-1]
        if not np.isnan(current_rsi) and 0 <= current_rsi <= 100:
            if current_rsi < self.config.rsi_buy_threshold:
                signals.append(1)
                confs.append(self.config.rsi_confidence)
                signal_reasons.append(f"RSI oversold: {current_rsi:.1f}")
            elif current_rsi > self.config.rsi_sell_threshold:
                signals.append(-1)
                confs.append(self.config.rsi_confidence)
                signal_reasons.append(f"RSI overbought: {current_rsi:.1f}")
        
        # EMA Cross
        if not np.isnan(ema_short[-1]) and not np.isnan(ema_long[-1]):
            if ema_short[-1] > ema_long[-1] and ema_short[-2] <= ema_long[-2]:
                cross_strength = abs(ema_short[-1] - ema_long[-1]) / ema_long[-1]
                if cross_strength > 0.0002:
                    signals.append(1)
                    confs.append(self.config.sma_cross_confidence)
                    signal_reasons.append("EMA bullish cross")
            elif ema_short[-1] < ema_long[-1] and ema_short[-2] >= ema_long[-2]:
                cross_strength = abs(ema_long[-1] - ema_short[-1]) / ema_long[-1]
                if cross_strength > 0.0002:
                    signals.append(-1)
                    confs.append(self.config.sma_cross_confidence)
                    signal_reasons.append("EMA bearish cross")
        
        # Bollinger Bands
        price = prices[-1]
        if not np.isnan(bb_lower[-1]) and not np.isnan(bb_upper[-1]):
            if price < bb_lower[-1] * 0.998:
                signals.append(1)
                confs.append(self.config.bb_confidence)
                signal_reasons.append("BB oversold")
            elif price > bb_upper[-1] * 1.002:
                signals.append(-1)
                confs.append(self.config.bb_confidence)
                signal_reasons.append("BB overbought")
        
        # Pattern
        if pattern_signal != 0:
            signals.append(pattern_signal)
            confs.append(self.config.pattern_confidence)
            signal_reasons.append(f"Pattern: {'Bullish' if pattern_signal > 0 else 'Bearish'}")
        
        # Consolidar
        if not signals:
            action = 'HOLD'
            overall_conf = 0.5
        else:
            signals_array = np.array(signals, dtype=np.float32)
            confs_array = np.array(confs, dtype=np.float32)
            
            if np.sum(confs_array) > 0:
                weighted = np.average(signals_array, weights=confs_array)
                overall_conf = float(np.mean(confs_array))
            else:
                weighted = 0
                overall_conf = 0.5
            
            if weighted > self.config.buy_threshold:
                action = 'BUY'
            elif weighted < -self.config.sell_threshold:
                action = 'SELL'
            else:
                action = 'HOLD'
        
        # Atualizar contadores
        self.signal_count[action] += 1
        
        # Log se significativo
        if action != 'HOLD':
            logger.info(f"üìä TA Sinal: {action} (conf: {overall_conf:.2%}) - RSI: {current_rsi:.1f}")
            logger.debug(f"   Raz√µes: {', '.join(signal_reasons)}")
        
        # Detalhes
        elapsed_ms = (time.perf_counter() - start_ts) * 1000
        details = {
            'rsi': float(current_rsi) if not np.isnan(current_rsi) else 50.0,
            'sma_short': float(sma_short[-1]) if not np.isnan(sma_short[-1]) else 0.0,
            'sma_long': float(sma_long[-1]) if not np.isnan(sma_long[-1]) else 0.0,
            'ema_short': float(ema_short[-1]) if not np.isnan(ema_short[-1]) else 0.0,
            'ema_long': float(ema_long[-1]) if not np.isnan(ema_long[-1]) else 0.0,
            'bb_upper': float(bb_upper[-1]) if not np.isnan(bb_upper[-1]) else 0.0,
            'bb_lower': float(bb_lower[-1]) if not np.isnan(bb_lower[-1]) else 0.0,
            'bb_position': ((price - bb_lower[-1]) / (bb_upper[-1] - bb_lower[-1]) 
                           if not np.isnan(bb_upper[-1]) and not np.isnan(bb_lower[-1]) 
                           and bb_upper[-1] > bb_lower[-1] else 0.5),
            'pattern': pattern_signal,
            'calc_time_ms': elapsed_ms,
            'current_price': float(price),
            'reasons': signal_reasons
        }
        
        self.last_calculation_time = now
        self._cached_signal = (action, overall_conf, details)
        return action, overall_conf, details
    
    def get_signal_stats(self) -> Dict:
        """Retorna estat√≠sticas dos sinais"""
        total = sum(self.signal_count.values())
        return {
            'total_signals': total,
            'buy_signals': self.signal_count['BUY'],
            'sell_signals': self.signal_count['SELL'],
            'hold_signals': self.signal_count['HOLD'],
            'buy_percentage': self.signal_count['BUY'] / total * 100 if total > 0 else 0,
            'sell_percentage': self.signal_count['SELL'] / total * 100 if total > 0 else 0
        }
''',

    "trade_system/cli.py": '''"""
Interface de linha de comando para o sistema de trading
"""
import os
import sys
import asyncio
import argparse
from datetime import datetime
from typing import Optional

# Adicionar diret√≥rio pai ao path se necess√°rio
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from trade_system.config import get_config, create_example_config
from trade_system.logging_config import setup_logging


def create_parser() -> argparse.ArgumentParser:
    """Cria parser de argumentos"""
    parser = argparse.ArgumentParser(
        description='Sistema de Trading Ultra-Otimizado v5.2',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:
  python -m trade_system.cli backtest              # Executa backtest
  python -m trade_system.cli backtest --debug      # Backtest em modo debug
  python -m trade_system.cli paper                 # Inicia paper trading
  python -m trade_system.cli paper --no-backtest   # Paper trading sem backtest
  python -m trade_system.cli config                # Cria config.yaml exemplo
        """
    )
    
    # Subcomandos
    subparsers = parser.add_subparsers(dest='command', help='Comandos dispon√≠veis')
    
    # Backtest
    backtest_parser = subparsers.add_parser('backtest', help='Executa backtest da estrat√©gia')
    backtest_parser.add_argument('--debug', action='store_true', help='Modo debug com par√¢metros agressivos')
    backtest_parser.add_argument('--days', type=int, default=7, help='Dias de dados hist√≥ricos (padr√£o: 7)')
    backtest_parser.add_argument('--symbol', type=str, help='Par de trading (ex: BTCUSDT)')
    
    # Paper Trading
    paper_parser = subparsers.add_parser('paper', help='Inicia paper trading com dados reais')
    paper_parser.add_argument('--debug', action='store_true', help='Modo debug')
    paper_parser.add_argument('--no-backtest', action='store_true', help='Pular backtest inicial')
    paper_parser.add_argument('--balance', type=float, default=10000, help='Balance inicial (padr√£o: 10000)')
    
    # Config
    config_parser = subparsers.add_parser('config', help='Gerenciar configura√ß√µes')
    config_parser.add_argument('--create', action='store_true', help='Criar config.yaml exemplo')
    config_parser.add_argument('--show', action='store_true', help='Mostrar configura√ß√£o atual')
    
    # Op√ß√µes globais
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                       default='INFO', help='N√≠vel de logging')
    parser.add_argument('--config-file', type=str, default='config.yaml', 
                       help='Arquivo de configura√ß√£o')
    
    return parser


async def run_backtest_command(args):
    """Executa comando de backtest"""
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    MODO BACKTEST                             ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    # TODO: Implementar backtest
    print("‚ùå Backtest ainda n√£o implementado nesta vers√£o modular")
    print("Em desenvolvimento...")


async def run_paper_trading_command(args):
    """Executa comando de paper trading"""
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  PAPER TRADING MODE                          ‚ïë
‚ïë              Execu√ß√£o simulada com dados reais               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    # TODO: Implementar paper trading
    print("‚ùå Paper Trading ainda n√£o implementado nesta vers√£o modular")
    print("Em desenvolvimento...")


def run_config_command(args):
    """Executa comando de configura√ß√£o"""
    if args.create:
        if os.path.exists('config.yaml'):
            confirm = input("config.yaml j√° existe. Sobrescrever? (s/n): ")
            if confirm.lower() != 's':
                print("Opera√ß√£o cancelada.")
                return
        
        create_example_config()
        print("‚úÖ config.yaml criado com sucesso!")
        print("\\nüìù Edite o arquivo para personalizar os par√¢metros")
    
    elif args.show:
        config = get_config()
        print("\\nüìã Configura√ß√£o atual:")
        print(f"Symbol: {config.symbol}")
        print(f"Min confidence: {config.min_confidence}")
        print(f"Max position: {config.max_position_pct*100}%")
        print(f"Debug mode: {config.debug_mode}")
        print(f"\\nPara ver todas as configura√ß√µes, abra config.yaml")


def main():
    """Fun√ß√£o principal do CLI"""
    parser = create_parser()
    args = parser.parse_args()
    
    # Configurar logging
    setup_logging(log_level=args.log_level)
    
    # Verificar comando
    if not args.command:
        parser.print_help()
        sys.exit(0)
    
    # Executar comando apropriado
    if args.command == 'backtest':
        asyncio.run(run_backtest_command(args))
    
    elif args.command == 'paper':
        asyncio.run(run_paper_trading_command(args))
    
    elif args.command == 'config':
        run_config_command(args)


if __name__ == '__main__':
    main()
''',

    "setup.py": '''"""
Setup para o Sistema de Trading Ultra-Otimizado
"""
from setuptools import setup, find_packages
import os

# Ler README se existir
long_description = ""
if os.path.exists("README.md"):
    with open("README.md", "r", encoding="utf-8") as fh:
        long_description = fh.read()

# Ler requirements se existir
requirements = []
if os.path.exists("requirements.txt"):
    with open("requirements.txt", "r") as f:
        requirements = [line.strip() for line in f if line.strip() and not line.startswith("#")]
else:
    # Requirements m√≠nimos
    requirements = [
        "numpy>=1.21.0",
        "numba>=0.54.0",
        "pandas>=1.3.0",
        "python-binance>=1.0.0",
        "pyyaml>=5.4.0",
        "aiohttp>=3.8.0",
        "redis>=4.0.0",
        "requests>=2.26.0",
    ]

setup(
    name="ultra-trading-system",
    version="5.2.0",
    author="Trading System Team",
    author_email="",
    description="Sistema de Trading Ultra-Otimizado com Paper Trading",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/yourusername/ultra-trading-system",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Financial and Insurance Industry",
        "Topic :: Office/Business :: Financial :: Investment",
        "License :: OSI Approved :: MIT License",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
    ],
    python_requires=">=3.8",
    install_requires=requirements,
    extras_require={
        "dev": [
            "pytest>=7.0.0",
            "pytest-asyncio>=0.18.0",
            "pytest-cov>=3.0.0",
            "black>=22.0.0",
            "flake8>=4.0.0",
            "mypy>=0.950",
        ],
    },
    entry_points={
        "console_scripts": [
            "trade-system=trade_system.cli:main",
            "trading=trade_system.cli:main",
        ],
    },
    include_package_data=True,
    package_data={
        "trade_system": ["*.yaml", "*.yml"],
    },
)
''',

    "requirements.txt": '''# Core dependencies
numpy>=1.21.0
numba>=0.54.0
pandas>=1.3.0
python-binance>=1.0.0

# Configuration
pyyaml>=5.4.0
python-dotenv>=0.19.0

# Async and networking
aiohttp>=3.8.0
requests>=2.26.0
websocket-client>=1.0.0

# Caching
redis>=4.0.0

# Development (optional)
pytest>=7.0.0
pytest-asyncio>=0.18.0
pytest-cov>=3.0.0
black>=22.0.0
flake8>=4.0.0
mypy>=0.950
''',

    "README.md": '''# Sistema de Trading Ultra-Otimizado v5.2

Sistema de trading algor√≠tmico de alta performance com an√°lise t√©cnica ultra-r√°pida, machine learning e paper trading.

## üöÄ Caracter√≠sticas

- **An√°lise T√©cnica Ultra-R√°pida**: Indicadores otimizados com Numba para lat√™ncia < 1ms
- **WebSocket em Tempo Real**: Dados de mercado com buffer otimizado
- **Machine Learning**: Predi√ß√µes adaptativas baseadas em padr√µes
- **Paper Trading**: Teste estrat√©gias com dados reais sem risco
- **Sistema de Alertas**: Notifica√ß√µes via Telegram e email
- **Gest√£o de Risco**: Prote√ß√µes avan√ßadas e stop loss din√¢mico
- **Cache Redis**: Performance m√°xima com fallback local
- **Rate Limiting**: Prote√ß√£o contra limites de API

## üì¶ Instala√ß√£o

### 1. Clone o reposit√≥rio
```bash
git clone https://github.com/yourusername/ultra-trading-system.git
cd ultra-trading-system
```

### 2. Crie ambiente virtual
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\\Scripts\\activate  # Windows
```

### 3. Instale o pacote
```bash
pip install -e .
```

### 4. Configure as credenciais
```bash
export BINANCE_API_KEY="sua_api_key"
export BINANCE_API_SECRET="sua_api_secret"

# Opcional - para alertas
export TELEGRAM_BOT_TOKEN="seu_token"
export TELEGRAM_CHAT_ID="seu_chat_id"
```

### 5. Crie arquivo de configura√ß√£o
```bash
trade-system config --create
```

## üéÆ Uso R√°pido

### Paper Trading (Recomendado)
```bash
# Iniciar paper trading com backtest de valida√ß√£o
trade-system paper

# Modo debug com par√¢metros agressivos
trade-system paper --debug

# Definir balance inicial
trade-system paper --balance 5000
```

### Backtest
```bash
# Backtest padr√£o (7 dias)
trade-system backtest

# Backtest com mais dados
trade-system backtest --days 30

# Backtest de outro par
trade-system backtest --symbol ETHUSDT
```

## ‚öôÔ∏è Configura√ß√£o

Edite `config.yaml` para personalizar:

```yaml
trading:
  symbol: "BTCUSDT"
  min_confidence: 0.75  # Confian√ßa m√≠nima para trades
  max_position_pct: 0.02  # M√°ximo 2% do balance por posi√ß√£o

risk:
  max_volatility: 0.05  # M√°xima volatilidade aceita
  max_spread_bps: 20  # M√°ximo spread em basis points
  max_daily_loss: 0.02  # Stop loss di√°rio de 2%

ta:
  rsi_buy_threshold: 30
  rsi_sell_threshold: 70
  # ... mais par√¢metros
```

## üìä Arquitetura

```
trade_system/
‚îú‚îÄ‚îÄ config.py             # Configura√ß√µes e par√¢metros
‚îú‚îÄ‚îÄ logging_config.py     # Sistema de logging centralizado
‚îú‚îÄ‚îÄ alerts.py             # Sistema de alertas multi-canal
‚îú‚îÄ‚îÄ cache.py              # Cache ultra-r√°pido com Redis
‚îú‚îÄ‚îÄ rate_limiter.py       # Controle de rate limiting
‚îú‚îÄ‚îÄ websocket_manager.py  # WebSocket para dados em tempo real
‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îú‚îÄ‚îÄ technical.py      # An√°lise t√©cnica com Numba
‚îÇ   ‚îú‚îÄ‚îÄ orderbook.py      # An√°lise de orderbook
‚îÇ   ‚îî‚îÄ‚îÄ ml.py             # Machine Learning simplificado
‚îú‚îÄ‚îÄ risk.py               # Gest√£o de risco e valida√ß√µes
‚îú‚îÄ‚îÄ backtester.py         # Sistema de backtesting
‚îú‚îÄ‚îÄ signals.py            # Consolida√ß√£o de sinais
‚îú‚îÄ‚îÄ checkpoint.py         # Sistema de checkpoints
‚îî‚îÄ‚îÄ cli.py                # Interface de linha de comando
```

## üîí Seguran√ßa

- **Paper Trading por Padr√£o**: Sempre teste em modo simulado primeiro
- **Valida√ß√µes de Mercado**: Prote√ß√£o contra condi√ß√µes extremas
- **Stop Loss Di√°rio**: Limite de perda configur√°vel
- **Rate Limiting**: Prote√ß√£o contra banimento de API
- **Checkpoints**: Recupera√ß√£o autom√°tica em caso de falha

## üìà Performance

- Lat√™ncia de an√°lise t√©cnica: < 1ms
- Throughput WebSocket: > 1000 msg/s
- Cache Redis: < 0.1ms de lat√™ncia
- Consumo de mem√≥ria: < 500MB t√≠pico

## ü§ù Contribuindo

1. Fork o projeto
2. Crie sua feature branch (`git checkout -b feature/amazing`)
3. Commit suas mudan√ßas (`git commit -m 'Add amazing feature'`)
4. Push para a branch (`git push origin feature/amazing`)
5. Abra um Pull Request

## ‚ö†Ô∏è Disclaimer

Este software √© fornecido "como est√°" para fins educacionais. Trading de criptomoedas envolve riscos substanciais. Sempre teste em paper trading antes de usar dinheiro real.

## üìù Licen√ßa

MIT License - veja LICENSE para detalhes.
''',

    ".gitignore": '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual Environment
venv/
ENV/
env/
.venv

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Project specific
logs/
checkpoints/
reports/
config.yaml
.env
*.log

# Data files
*.csv
*.pkl
*.json
*.db

# OS
.DS_Store
Thumbs.db

# Testing
.coverage
.pytest_cache/
htmlcov/
.tox/
.nox/
coverage.xml
*.cover
.hypothesis/

# Documentation
docs/_build/
.docx
''',

    "LICENSE": '''MIT License

Copyright (c) 2024 Trading System Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
''',

    ".env.example": '''# Binance API (necess√°rio)
BINANCE_API_KEY=sua_api_key_aqui
BINANCE_API_SECRET=sua_api_secret_aqui

# Telegram Alerts (opcional)
TELEGRAM_BOT_TOKEN=seu_bot_token_aqui
TELEGRAM_CHAT_ID=seu_chat_id_aqui

# Redis (opcional - para cache)
REDIS_HOST=localhost
REDIS_PORT=6379
''',
}


def create_project_structure():
    """Cria estrutura completa do projeto em um arquivo ZIP"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    zip_filename = f"trading_system_v5.2_{timestamp}.zip"
    
    print(f"üì¶ Criando arquivo ZIP: {zip_filename}")
    
    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for filepath, content in FILES.items():
            print(f"   ‚úÖ Adicionando: {filepath}")
            
            # Adicionar arquivo ao ZIP
            zipf.writestr(filepath, content)
    
    # Calcular tamanho do arquivo
    size_mb = os.path.getsize(zip_filename) / (1024 * 1024)
    
    print(f"\n‚úÖ Arquivo criado com sucesso!")
    print(f"üìä Tamanho: {size_mb:.2f} MB")
    print(f"üìÅ Nome: {zip_filename}")
    print(f"\nüìã Instru√ß√µes de instala√ß√£o:")
    print(f"1. Extraia o arquivo: unzip {zip_filename}")
    print(f"2. Entre no diret√≥rio: cd trading_system_v5.2")
    print(f"3. Crie ambiente virtual: python -m venv venv")
    print(f"4. Ative o ambiente: source venv/bin/activate")
    print(f"5. Instale o pacote: pip install -e .")
    print(f"6. Configure credenciais: cp .env.example .env && nano .env")
    print(f"7. Crie config: trade-system config --create")
    print(f"8. Execute: trade-system paper")
    
    return zip_filename


if __name__ == "__main__":
    print("="*60)
    print("Sistema de Trading Ultra-Otimizado v5.2")
    print("Gerador de Projeto Completo")
    print("="*60)
    
    try:
        zip_file = create_project_structure()
        print(f"\nüéâ Sucesso! O arquivo '{zip_file}' est√° pronto para uso.")
    except Exception as e:
        print(f"\n‚ùå Erro ao criar o arquivo ZIP: {e}")
        import traceback
        traceback.print_exc()